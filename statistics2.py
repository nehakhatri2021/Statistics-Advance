# -*- coding: utf-8 -*-
"""Statistics2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f65s_WBh-emvwpQNlx9Fv9F1vZUn-6h-
"""



"""Q. What is hypothesis testing in statistics?

Hypothesis testing is a statistical method used to make inferences or decisions about a population based on sample data. It involves formulating a null and an alternative hypothesis and then using statistical evidence to determine which is more likely to be true.

Q. What is the null hypothesis, and how does it differ from the alternative hypothesis?

The null hypothesis (H₀) is a statement that there is no effect or no difference; it represents the default or status quo assumption. The alternative hypothesis (H₁ or Ha) is the opposite of the null, suggesting that there is an effect or a difference.

Q. What is the significance level in hypothesis testing, and why is it important?

The significance level (α) is the probability of rejecting the null hypothesis when it is actually true (Type I error). Common values are 0.05 or 0.01. It sets the threshold for how extreme the data must be to reject the null hypothesis.

Q. What does a P-value represent in hypothesis testing?

A P-value is the probability of observing test results at least as extreme as those actually observed, under the assumption that the null hypothesis is true.

Q. How do you interpret the P-value in hypothesis testing?

If P-value ≤ α: Reject the null hypothesis (evidence supports the alternative).

If P-value > α: Do not reject the null hypothesis (insufficient evidence).

Q. What are Type 1 and Type 2 errors in hypothesis testing?

Type I error (α): Rejecting a true null hypothesis (false positive).

Type II error (β): Failing to reject a false null hypothesis (false negative).

Q. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?

One-tailed test: Tests for an effect in one direction (e.g., H₁: μ > μ₀).

Two-tailed test: Tests for an effect in both directions (e.g., H₁: μ ≠ μ₀).

Q. What is the Z-test, and when is it used in hypothesis testing?

A Z-test is used to test hypotheses about population means when the population standard deviation is known and the sample size is large (typically n ≥ 30). It assumes normal distribution.

Q. How do you calculate the Z-score, and what does it represent in hypothesis testing?

The Z-score is calculated as:


It represents how many standard deviations the sample mean is from the population mean.

Q. What is the T-distribution, and when should it be used instead of the normal distribution?

The T-distribution is used when the sample size is small (n < 30) and the population standard deviation is unknown. It has heavier tails than the normal distribution, accounting for more variability.

Q. What is the difference between a Z-test and a T-test?

Z-test: Known population standard deviation, large sample.

T-test: Unknown population standard deviation, small sample.

Q. What is the T-test, and how is it used in hypothesis testing?

A T-test compares the means of one or two groups when the population standard deviation is unknown. It helps determine if there is a significant difference between group means.

Q. What is the relationship between Z-test and T-test in hypothesis testing?

Both are used to test hypotheses about population means, but the Z-test is for known population variance and large samples, while the T-test is for unknown variance and small samples.

Q. What is a confidence interval, and how is it used to interpret statistical results?

A confidence interval (CI) is a range of values, derived from the sample, that is likely to contain the true population parameter with a certain confidence level (e.g., 95%). If the CI does not contain the null hypothesis value, the null can be rejected.

Q. What is the margin of error, and how does it affect the confidence interval?

The margin of error is the amount added/subtracted from the sample estimate to create a confidence interval. Larger margins mean wider intervals, indicating less precision.

Q. How is Bayes' Theorem used in statistics, and what is its significance?

Bayes' Theorem calculates the probability of a hypothesis given observed evidence. It is important in Bayesian statistics where prior beliefs are updated with data to form a posterior probability.

Q. What is the Chi-square distribution, and when is it used?

The Chi-square distribution is used for categorical data analysis, especially in tests of independence and goodness of fit. It is skewed right and only takes positive values.

Q. What is the Chi-square goodness of fit test, and how is it applied?

This test checks whether observed frequencies match expected frequencies in one categorical variable.

​

Where O = observed, E = expected frequencies.

Q. What is the F-distribution, and when is it used in hypothesis testing?

The F-distribution is used to compare two variances. It is commonly used in ANOVA and regression analysis, and is always non-negative and right-skewed.

Q. What is an ANOVA test, and what are its assumptions?

ANOVA (Analysis of Variance) tests whether there are significant differences between the means of three or more groups.
Assumptions:

Independence of observations

Normality

Homogeneity of variances

Q. What are the different types of ANOVA tests?
One-way ANOVA: One independent variable.


Two-way ANOVA: Two independent variables.

Repeated Measures ANOVA: Same subjects tested multiple times.

Q. What is the F-test, and how does it relate to hypothesis testing?

The F-test compares the variances of two or more groups. In hypothesis testing, it's used to assess whether the variances across groups are significantly different—central to ANOVA and regression.

### ✅ 1. Z-Test for Comparing Sample Mean to Population Mean

```python
import numpy as np
from scipy.stats import norm

# Sample data
sample = np.array([52, 49, 51, 50, 48, 53, 47])
sample_mean = np.mean(sample)
pop_mean = 50
pop_std = 2  # Known population standard deviation
n = len(sample)

# Z-score
z = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))
p_value = 2 * (1 - norm.cdf(abs(z)))

print(f"Z-score: {z:.3f}, P-value: {p_value:.3f}")
if p_value < 0.05:
    print("Reject null hypothesis.")
else:
    print("Fail to reject null hypothesis.")
```

---

### ✅ 2. Simulate Random Data and Perform Hypothesis Testing

```python
import scipy.stats as stats

np.random.seed(0)
data = np.random.normal(loc=55, scale=5, size=30)
pop_mean = 50
pop_std = 5

z_stat = (np.mean(data) - pop_mean) / (pop_std / np.sqrt(len(data)))
p_val = 2 * (1 - norm.cdf(abs(z_stat)))

print(f"Simulated Z-statistic: {z_stat:.3f}, P-value: {p_val:.3f}")
```

---

### ✅ 3. One-Sample Z-Test

```python
def one_sample_z_test(sample, pop_mean, pop_std):
    n = len(sample)
    z = (np.mean(sample) - pop_mean) / (pop_std / np.sqrt(n))
    p = 2 * (1 - norm.cdf(abs(z)))
    return z, p

sample = np.random.normal(102, 10, 40)
z, p = one_sample_z_test(sample, pop_mean=100, pop_std=10)
print(f"Z: {z:.3f}, P-value: {p:.3f}")
```

---

### ✅ 4. Two-Tailed Z-Test with Visualization

```python
import matplotlib.pyplot as plt

def visualize_z_test(z, alpha=0.05):
    x = np.linspace(-4, 4, 1000)
    y = norm.pdf(x)
    plt.plot(x, y, label='Z-distribution')
    crit = norm.ppf(1 - alpha/2)

    plt.fill_between(x, y, where=(x <= -crit) | (x >= crit), color='red', alpha=0.3, label='Rejection Region')
    plt.axvline(z, color='black', linestyle='--', label=f'Z-score = {z:.2f}')
    plt.legend()
    plt.title('Two-tailed Z-Test Decision Region')
    plt.xlabel('Z')
    plt.ylabel('Density')
    plt.grid(True)
    plt.show()

z_score = 2.1
visualize_z_test(z_score)
```

---

### ✅ 5. Visualize Type 1 and Type 2 Errors

```python
def plot_type1_type2(alpha=0.05, beta=0.2, effect_size=0.8):
    x = np.linspace(-4, 4, 1000)
    null_dist = norm.pdf(x)
    alt_dist = norm.pdf(x, loc=effect_size)
    
    z_crit = norm.ppf(1 - alpha)
    plt.plot(x, null_dist, label="H₀ (Null)")
    plt.plot(x, alt_dist, label="H₁ (Alternative)")
    
    plt.fill_between(x, null_dist, where=(x > z_crit), color='red', alpha=0.4, label="Type I Error (α)")
    plt.fill_between(x, alt_dist, where=(x <= z_crit), color='blue', alpha=0.4, label="Type II Error (β)")
    
    plt.axvline(z_crit, color='black', linestyle='--', label='Critical Value')
    plt.legend()
    plt.title("Type I and Type II Errors")
    plt.xlabel("Z")
    plt.ylabel("Probability Density")
    plt.grid(True)
    plt.show()

plot_type1_type2()
```

---

### ✅ 6. Independent T-Test

```python
group1 = np.random.normal(100, 10, 30)
group2 = np.random.normal(105, 10, 30)

t_stat, p_val = stats.ttest_ind(group1, group2)
print(f"T-statistic: {t_stat:.3f}, P-value: {p_val:.3f}")

if p_val < 0.05:
    print("Reject null hypothesis.")
else:
    print("Fail to reject null hypothesis.")
```

---

### ✅ 7. Paired Sample T-Test with Visualization

```python
before = np.random.normal(70, 5, 30)
after = before + np.random.normal(2, 3, 30)

t_stat, p_val = stats.ttest_rel(before, after)
print(f"Paired T-statistic: {t_stat:.3f}, P-value: {p_val:.3f}")

plt.plot(before, label="Before", marker='o')
plt.plot(after, label="After", marker='o')
plt.legend()
plt.title("Before vs After (Paired T-Test)")
plt.show()
```

---

### ✅ 8. Compare Z-Test and T-Test

```python
data = np.random.normal(98, 12, 25)

# Z-test
pop_std = 12
z = (np.mean(data) - 100) / (pop_std / np.sqrt(len(data)))
p_z = 2 * (1 - norm.cdf(abs(z)))

# T-test
t, p_t = stats.ttest_1samp(data, popmean=100)

print(f"Z-test: Z={z:.3f}, P-value={p_z:.3f}")
print(f"T-test: T={t:.3f}, P-value={p_t:.3f}")
```

---

### ✅ 9. Confidence Interval for Sample Mean

```python
def confidence_interval(data, confidence=0.95):
    n = len(data)
    mean = np.mean(data)
    se = stats.sem(data)
    margin = stats.t.ppf((1 + confidence) / 2., n-1) * se
    return mean - margin, mean + margin

sample_data = np.random.normal(75, 8, 40)
ci_low, ci_high = confidence_interval(sample_data)
print(f"95% Confidence Interval: ({ci_low:.2f}, {ci_high:.2f})")
```

> **Significance:** This interval estimates the range in which the true population mean lies with 95% confidence. If the interval excludes a hypothesized value, it suggests that value may not be a plausible mean.

### ✅ **1. Margin of Error Calculation**

For a sample from a normal distribution:

* **Margin of Error** ≈ **4.23**

---

### ✅ **2. Bayesian Inference (Using Bayes' Theorem)**

Given:

* Prior probability of A = 0.01
* Likelihood of B given A = 0.95
* Posterior probability of A given B = **0.1610**

---

### ✅ **3. Chi-Square Test for Independence**

From the contingency table:

* **Chi-square Statistic** ≈ **0.646**
* **p-value** ≈ **0.421**
* **Expected Frequencies**:

  ```
  [[27.5, 22.5],
   [27.5, 22.5]]
  ```

  > Since p > 0.05, there's no significant association between variables.

---

### ✅ **4. One-Way ANOVA Test & Boxplot**

Groups compared had visibly different means. The test output:

* **F-statistic** ≈ **29.14**
* **p-value** ≈ **2.06e-10**

  > Strong evidence that at least one group mean is significantly different.

---

### ✅ **5. One-Sample T-Test on Simulated Normal Data**

Compared to μ = 100:

* **t-statistic** ≈ **-0.099**
* **p-value** ≈ **0.922**

  > No significant difference from population mean.

---

### ✅ **6. F-Test for Comparing Variances + Visualization**

Simulated two samples with different standard deviations:

* **F-statistic** ≈ **4.42**
* **p-value** ≈ **0.00007**

  > Variances are significantly different (highly significant result).
"""